{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import ipywidgets\n",
    "\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from functools import reduce\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUALITY_HATCH = False\n",
    "DATA_QUALITY_THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = os.path.join('..', '..', 'data')\n",
    "PATH_DATA_SOURCE = os.path.join(PATH_DATA, 'raw_data')\n",
    "PATH_MODELS = os.path.join(PATH_DATA, 'models', 'mev_nn')\n",
    "PATH_SHAPEFILE = os.path.join(PATH_DATA_SOURCE, 'geodata', 'AUT_adm0.shp')\n",
    "FOLDERS = os.listdir(PATH_MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERS.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the desired training cycle\n",
    "cycle = ipywidgets.Select(\n",
    "    options=FOLDERS,\n",
    "    value=FOLDERS[0],\n",
    "    # rows=10,\n",
    "    description='Choose Training cycle:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select the file for the desired return level\n",
    "FILES = glob.glob(os.path.join(PATH_MODELS, cycle.value, 'returns*.csv'))\n",
    "FILE_NAMES = [os.path.basename(x) for x in glob.glob(os.path.join(PATH_MODELS, cycle.value, 'returns*.csv'))]\n",
    "csv_files = ipywidgets.SelectMultiple(\n",
    "    options=FILE_NAMES,\n",
    "    value=FILE_NAMES,\n",
    "    # rows=10,\n",
    "    description='Choose return period:',\n",
    "    disabled=False\n",
    ")\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_append = []\n",
    "#append all files together\n",
    "for file in csv_files.value:\n",
    "            df_temp = pd.read_csv(os.path.join(PATH_MODELS, cycle.value, file))\n",
    "            df_temp['target'] /= 10\n",
    "            df_temp.rename(columns={'target': file}, inplace=True)\n",
    "            df_append.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_data = reduce(lambda x, y: pd.merge(x, y, on = ['lon', 'lat'], how='outer'), df_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUALITY_HATCH:\n",
    "    quality_reports = glob.glob(os.path.join(PATH_DATA_SOURCE, 'ZAMG', 'dataquality_map', '2023_12_04','*.h5'))\n",
    "    quality_file = h5py.File(quality_reports[0])\n",
    "\n",
    "    data_lat = quality_file[\"atnt_grid_lat\"][:]\n",
    "    data_lon = quality_file[\"atnt_grid_lon\"][:]\n",
    "    data_quality = quality_file['data'][:]\n",
    "\n",
    "    data_xr_quality = xr.DataArray(\n",
    "                            data_quality,\n",
    "                            coords=dict(\n",
    "                                lon=([\"y\", \"x\"], data_lon),\n",
    "                                lat=([\"y\", \"x\"], data_lat),\n",
    "                            ),\n",
    "                            dims=[\"y\", \"x\"],\n",
    "                            name = 'quality'\n",
    "                        )\n",
    "\n",
    "    data_pandas_quality = data_xr_quality.to_dataframe()\n",
    "    data_schraffur_quality = data_pandas_quality[(data_pandas_quality['quality'].isna()) | (data_pandas_quality['quality'] < DATA_QUALITY_THRESHOLD)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if QUALITY_HATCH:\n",
    "    elevation_reports = glob.glob(os.path.join(PATH_DATA_SOURCE, 'ZAMG', 'dataquality_map', '2023_11_20','*.h5'))\n",
    "    elevation_file = h5py.File(elevation_reports[0])\n",
    "\n",
    "    data_lat_elevation = elevation_file[\"atnt_grid_lat\"][:]\n",
    "    data_lon_elevation = elevation_file[\"atnt_grid_lon\"][:]\n",
    "    data_elevation = elevation_file['data'][:]\n",
    "\n",
    "    data_xr_elevation = xr.DataArray(\n",
    "                            data_elevation,\n",
    "                            coords=dict(\n",
    "                                lon=([\"y\", \"x\"], data_lon_elevation),\n",
    "                                lat=([\"y\", \"x\"], data_lat_elevation),\n",
    "                            ),\n",
    "                            dims=[\"y\", \"x\"],\n",
    "                            name = 'elevation'\n",
    "                        )\n",
    "    \n",
    "    data_pandas_elevation = data_xr_elevation.to_dataframe()\n",
    "    data_schraffur_elevation = data_pandas_elevation[(data_pandas_elevation['elevation'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(return_data['lon'], return_data['lat'])]\n",
    "gdf = gpd.GeoDataFrame(return_data, geometry=geometry, crs=\"EPSG:4326\")\n",
    "austria = gpd.read_file(PATH_SHAPEFILE)\n",
    "return_data_clipped = gpd.sjoin(gdf, austria, how=\"inner\", predicate='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files.value:\n",
    "    print(f\"Processing {file}\", flush=True)\n",
    "\n",
    "    for clip_to_austria in [False, True]:\n",
    "        infix_clipped = \"_clipped_AUT\" if clip_to_austria else \"\"\n",
    "\n",
    "        return_data_tmp = return_data_clipped if clip_to_austria else return_data\n",
    "        \n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "        #initialize the Basemap\n",
    "        m = Basemap(projection = 'lcc', resolution='f', lat_0=47.5, lon_0=13.3, width=0.6E6, height=3.7E5)\n",
    "        m.drawmapboundary()\n",
    "        m.drawcountries(linewidth=2)\n",
    "    \n",
    "        m.scatter(return_data_tmp['lon'], return_data_tmp['lat'], c=return_data_tmp[file], cmap=\"jet\", marker=',', s=0.7, latlon=True, vmin=1, vmax=6)\n",
    "    \n",
    "        plt.colorbar(label='MEHS', extend=\"max\")\n",
    "    \n",
    "        plt.savefig(os.path.join(PATH_MODELS, cycle.value, f\"hailriskat_{file}{infix_clipped}.pdf\"), bbox_inches=\"tight\")\n",
    "        plt.savefig(os.path.join(PATH_MODELS, cycle.value, f\"hailriskat_{file}{infix_clipped}.png\"), bbox_inches=\"tight\")\n",
    "    \n",
    "        if QUALITY_HATCH:\n",
    "            print(f\"Processing {file} (hatched)\", flush=True)\n",
    "            m.scatter(data_schraffur_quality['lon'], data_schraffur_quality['lat'], s=0.01, edgecolor='black', linewidth=3, latlon=True, facecolor='black', hatch='x')\n",
    "            m.scatter(data_schraffur_elevation['lon'], data_schraffur_elevation['lat'], s=0.01, edgecolor='black', linewidth=3, latlon=True, facecolor='black', hatch='x')\n",
    "            plt.savefig(os.path.join(PATH_MODELS, cycle.value, f\"hailriskat_{file}{infix_clipped}_hatched.pdf\"), bbox_inches=\"tight\")\n",
    "            plt.savefig(os.path.join(PATH_MODELS, cycle.value, f\"hailriskat_{file}{infix_clipped}_hatched.png\"), bbox_inches=\"tight\")\n",
    "    \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "        '(0, 2] cm' : '#C875C4',\n",
    "        '(2, 3] cm' : '#579DF7', \n",
    "        '(3, 4] cm' : '#A4F885',\n",
    "        '(4, 5] cm' : '#F3AE33',\n",
    "        '> 5cm' : '#8F383F',\n",
    "}\n",
    "\n",
    "for file in csv_files.value:\n",
    "    print(f\"Processing {file}\", flush=True)\n",
    "\n",
    "    for clip_to_austria in [False, True]:            \n",
    "        infix_clipped = \"_clipped_AUT\" if clip_to_austria else \"\"\n",
    "\n",
    "        return_data_tmp = return_data_clipped.copy() if clip_to_austria else return_data.copy()\n",
    "    \n",
    "        return_data_tmp.loc[:, 'cat_string'] = np.select(\n",
    "            [\n",
    "                (return_data_tmp[file] > 0) & (return_data_tmp[file] < 2), \n",
    "                (return_data_tmp[file] >= 2) & (return_data_tmp[file] < 3), \n",
    "                (return_data_tmp[file] >= 3) & (return_data_tmp[file] < 4), \n",
    "                (return_data_tmp[file] >= 4) & (return_data_tmp[file] < 5), \n",
    "                (return_data_tmp[file] >= 5),\n",
    "            ], \n",
    "            [\n",
    "                list(colors.keys())[0],\n",
    "                list(colors.keys())[1],\n",
    "                list(colors.keys())[2],\n",
    "                list(colors.keys())[3],\n",
    "                list(colors.keys())[4],\n",
    "            ], \n",
    "            default='ERROR'\n",
    "        )\n",
    "\n",
    "        return_data_tmp.query(\"cat_string != 'ERROR'\", inplace=True)\n",
    "    \n",
    "        ax = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "        #initialize the Basemap\n",
    "        m = Basemap(projection='lcc', resolution='f', lat_0=47.5, lon_0=13.3, width=0.6E6, height=3.7E5)\n",
    "        m.drawmapboundary()\n",
    "        m.drawcountries(linewidth=2)\n",
    "    \n",
    "        for cat in np.unique(return_data_tmp['cat_string']):\n",
    "            return_data_cat = return_data_tmp.query(f'cat_string == \"{cat}\"') \n",
    "            \n",
    "            m.scatter(return_data_cat['lon'], return_data_cat['lat'], c=colors[cat], latlon=True, label=cat, marker=',', s=0.7, alpha=1)\n",
    "    \n",
    "        # Plot legend.\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(0.9, 0.5), markerscale=10)\n",
    "    \n",
    "        plt.savefig(os.path.join(PATH_MODELS, cycle.value, f\"hailriskat_{file}{infix_clipped}_classification.pdf\"), bbox_inches=\"tight\")\n",
    "        plt.savefig(os.path.join(PATH_MODELS, cycle.value, f\"hailriskat_{file}{infix_clipped}_classification.png\"), bbox_inches=\"tight\")\n",
    "        \n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
