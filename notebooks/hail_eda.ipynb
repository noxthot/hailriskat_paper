{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cmasher as cmr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = os.path.join('..', 'data')\n",
    "PATH_PROCESSED = os.path.join(PATH_DATA, \"processed_data\")\n",
    "\n",
    "FOLDERS = [folder for folder in os.listdir(PATH_PROCESSED) if folder.startswith('dataparquet')]\n",
    "FOLDERS.sort(reverse=True)\n",
    "\n",
    "DIR_DATABUNDLE = FOLDERS[0]\n",
    "\n",
    "PATH_OUTPUT = os.path.join(PATH_DATA, \"hail_eda_plots\", DIR_DATABUNDLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"data_mehs_orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PATH_OUTPUT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet(os.path.join(PATH_PROCESSED, DIR_DATABUNDLE))\n",
    "\n",
    "df_full[\"lon\"] /= 1000000\n",
    "df_full[\"lat\"] /= 1000000\n",
    "\n",
    "if \"mehs\" in target_col:\n",
    "    df_full[target_col] /= 10  # convert to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cmr.get_sub_cmap('plasma', 0.05, 0.9)\n",
    "cmap.set_extremes(over=plt.colormaps.get_cmap('plasma')(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of hail days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = 1\n",
    "  \n",
    "print(f\"Computing plots for column {target_col}\", flush=True)\n",
    "    \n",
    "## Prepare dataframe\n",
    "df_speccolumn = df_full[[\"lon\", \"lat\", target_col]].copy()\n",
    "\n",
    "df_speccolumn.loc[:, \"sees_hail\"] = df_speccolumn[target_col] > 0\n",
    "\n",
    "df_agg = df_speccolumn.groupby(['lon', 'lat']).agg({\"sees_hail\" : ['sum']}).reset_index()\n",
    "df_agg.columns = [c[0] for c in list(df_agg.columns)[:2]] + ['hail_events']\n",
    "\n",
    "filename = f\"hailriskat_{target_col}_nr_observations\"\n",
    "\n",
    "df_agg.to_csv(os.path.join(PATH_OUTPUT, f\"{filename}.csv\"), index=False)\n",
    "\n",
    "vmax = df_agg['hail_events'].max()\n",
    "\n",
    "## Plot\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "ax = plt.figure(figsize=(15, 10))\n",
    "\n",
    "m = Basemap(projection='lcc', resolution='f', lat_0=47.7, lon_0=13.3, width=6.0E5, height=3.35E5)\n",
    "m.drawmapboundary()\n",
    "m.drawcountries(linewidth=2)\n",
    "\n",
    "m.scatter(df_agg['lon'], df_agg['lat'], c=df_agg['hail_events'], cmap=cmap, s=2, latlon=True, vmin=vmin, vmax=vmax)\n",
    "\n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.png\"), bbox_inches=\"tight\")\n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "fig = plt.figure(figsize=(3, 8))\n",
    "ax1 = fig.add_axes([0.05, 0.80, 0.2, 0.9])\n",
    "\n",
    "cb1 = mpl.colorbar.ColorbarBase(\n",
    "                                    ax1,\n",
    "                                    cmap=cmap,\n",
    "                                    norm=mpl.colors.Normalize(vmin=vmin, vmax=vmax),\n",
    "                                    orientation='vertical'\n",
    ")\n",
    "\n",
    "cb1.set_label('hail days')\n",
    "\n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.png\"), bbox_inches=\"tight\")\n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "print(\"Fin.\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hail frequency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hailsizes_to_plot = [0, 1, 2, 3, 4, 5]\n",
    "vmin = 0\n",
    "vmax = 2\n",
    "\n",
    "os.makedirs(PATH_OUTPUT, exist_ok=True)\n",
    "\n",
    "for hailsize in hailsizes_to_plot:\n",
    "    print(f\"Computing plots for hailsize {hailsize}\", flush=True)\n",
    "        \n",
    "    ## Prepare dataframe\n",
    "    df_speccolumn = df_full[[\"lon\", \"lat\", target_col]].copy()\n",
    "\n",
    "    df_speccolumn.loc[:, \"hail_larger_threshold\"] = (df_speccolumn[target_col] >= hailsize) if hailsize > 0 else (df_speccolumn[target_col] > hailsize)\n",
    "\n",
    "    df_agg = df_speccolumn.groupby(['lon', 'lat']).agg({\"hail_larger_threshold\" : ['sum']}).reset_index()\n",
    "    df_agg.columns = [c[0] for c in list(df_agg.columns)[:2]] + ['hail_events_larger_threshold']\n",
    "    df_agg = df_agg[df_agg['hail_events_larger_threshold'] > 0]\n",
    "    \n",
    "    filename = f\"hailriskat_{hailsize}_{target_col}\"\n",
    "    \n",
    "    df_agg.to_csv(os.path.join(PATH_OUTPUT, f\"{filename}.csv\"), index=False)\n",
    "\n",
    "    ## Plot\n",
    "    plt.rcParams.update({'font.size': 35})\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "    m = Basemap(projection='lcc', resolution='f', lat_0=47.7, lon_0=13.3, width=6.0E5, height=3.35E5)\n",
    "    m.drawmapboundary()\n",
    "    m.drawcountries(linewidth=2)\n",
    "\n",
    "    m.scatter(df_agg['lon'], df_agg['lat'], c=(df_agg['hail_events_larger_threshold'] / 14.0), cmap=cmap, s=2, latlon=True, vmin=vmin, vmax=vmax)\n",
    "\n",
    "    plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.png\"), bbox_inches=\"tight\")\n",
    "    plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    fig = plt.figure(figsize=(8, 3))\n",
    "    ax1 = fig.add_axes([0.05, 0.80, 0.9, 0.05])\n",
    "\n",
    "    cb1 = mpl.colorbar.ColorbarBase(\n",
    "                                        ax1,\n",
    "                                        cmap=cmap,\n",
    "                                        extend='max',\n",
    "                                        norm=mpl.colors.Normalize(vmin=vmin, vmax=vmax),\n",
    "                                        orientation='horizontal'\n",
    "    )\n",
    "    \n",
    "    cb1.set_label('Frequency per year')\n",
    "    \n",
    "    plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.png\"), bbox_inches=\"tight\")\n",
    "    plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "print(\"Fin.\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum hailstone size in observation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = 0\n",
    "vmax = 5\n",
    "       \n",
    "print(f\"Computing maximum estimated hailstone size plot\", flush=True)\n",
    "    \n",
    "## Prepare dataframe\n",
    "df_speccolumn = df_full[[\"lon\", \"lat\", target_col]].copy()\n",
    "\n",
    "df_agg = df_speccolumn.groupby(['lon', 'lat']).agg({target_col : ['max']}).reset_index()\n",
    "df_agg.columns = [c[0] for c in list(df_agg.columns)[:2]] + ['hail_max_observed']\n",
    "\n",
    "filename = f\"hailriskat_max_{target_col}\"\n",
    "    \n",
    "df_agg.to_csv(os.path.join(PATH_OUTPUT, f\"{filename}.csv\"), index=False)\n",
    "\n",
    "## Plot\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "ax = plt.figure(figsize = (15, 10))\n",
    "\n",
    "m = Basemap(projection='lcc', resolution='f', lat_0=47.7, lon_0=13.3, width=6.0E5, height=3.35E5)\n",
    "m.drawmapboundary()\n",
    "m.drawcountries(linewidth=2)\n",
    "\n",
    "m.scatter(df_agg['lon'], df_agg['lat'], c=df_agg['hail_max_observed'], cmap=cmap, s=2, latlon=True, vmin=vmin, vmax=vmax)\n",
    "\n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.png\"), bbox_inches=\"tight\")\n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "fig = plt.figure(figsize=(3, 8))\n",
    "ax1 = fig.add_axes([0.05, 0.80, 0.2, 0.9])\n",
    "\n",
    "cb1 = mpl.colorbar.ColorbarBase(\n",
    "                                    ax1,\n",
    "                                    cmap=cmap,\n",
    "                                    extend='max',\n",
    "                                    norm=mpl.colors.Normalize(vmin=vmin, vmax=vmax),\n",
    "                                    orientation='vertical'\n",
    ")\n",
    "\n",
    "cb1.set_label('hailstone size [cm]')\n",
    "    \n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.png\"), bbox_inches=\"tight\")\n",
    "plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "print(\"Fin.\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing sampled return level plots (bootstrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "n_iterations = 10\n",
    "years = np.arange(2009, 2023)\n",
    "n_years_samples = [10]\n",
    "\n",
    "for n_years_sample in n_years_samples:       \n",
    "    print(f\"Computing sampled return levels for {n_years_sample} years\", flush=True)\n",
    "\n",
    "    ## Prepare dataframe\n",
    "    df_speccolumn = df_full[[\"lon\", \"lat\", target_col]].copy()\n",
    "    df_speccolumn[\"year\"] = df_full[\"date\"].dt.year\n",
    "\n",
    "    df_agg = df_speccolumn.groupby(['lon', 'lat', 'year']).agg({target_col : ['max']}).reset_index()\n",
    "    df_agg.columns = [c[0] for c in list(df_agg.columns)[:3]] + ['hail_max_observed']\n",
    "\n",
    "    bootstrap_results = []\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        sampled_years = np.random.choice(years, n_years_sample, replace=False)\n",
    "        df_sampled = df_agg[df_agg['year'].isin(sampled_years)]\n",
    "        df_grouped = df_sampled.groupby(['lon', 'lat']).agg({'hail_max_observed': 'max'}).reset_index()\n",
    "        bootstrap_results.append(df_grouped)\n",
    "\n",
    "    print(f\"Summarizing results\", flush=True)\n",
    "    df_bootstrap = pd.concat(bootstrap_results)\n",
    "    df_bootstrap_mean = df_bootstrap.groupby(['lon', 'lat']).agg({'hail_max_observed': ['median', 'std']}).reset_index()\n",
    "    df_bootstrap_mean.columns = [c[0] for c in list(df_bootstrap_mean.columns)[:2]] + [c[1] for c in list(df_bootstrap_mean.columns)[2:]]\n",
    "\n",
    "    print(f\"Computing statistics\", flush=True)\n",
    "    df_bootstrap_mean[\"2std\"] = 2 * df_bootstrap_mean['std']\n",
    "    df_bootstrap_mean[\"median_1lc\"] = np.maximum(df_bootstrap_mean['median'] - df_bootstrap_mean['std'], 0)\n",
    "    df_bootstrap_mean[\"median_1uc\"] = df_bootstrap_mean['median'] + df_bootstrap_mean['std']\n",
    "    df_bootstrap_mean[\"median_2lc\"] = np.maximum(df_bootstrap_mean['median'] - df_bootstrap_mean['2std'], 0)\n",
    "    df_bootstrap_mean[\"median_2uc\"] = df_bootstrap_mean['median'] + df_bootstrap_mean['2std']\n",
    "\n",
    "    print(f\"Plotting\", flush=True)\n",
    "    for column in df_bootstrap_mean.columns:\n",
    "        if column in ['lon', 'lat', 'std']:\n",
    "            continue\n",
    "\n",
    "        if \"std\" in column:\n",
    "            vmin = 0\n",
    "            vmax = df_bootstrap_mean[column].max()\n",
    "\n",
    "            if column == \"2std\":\n",
    "                plttitle = f\"Two standard deviation of sampled {n_years_sample} year return level\"\n",
    "            elif column == \"std\":\n",
    "                plttitle = f\"Standard deviation of sampled {n_years_sample} year return level\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown column {column}\")\n",
    "        else:\n",
    "            vmin = 1\n",
    "            vmax = 5\n",
    "            plttitle = f\"Sampled {n_years_sample} year return level\"\n",
    "\n",
    "        filename = f\"hailriskat_sampled_return_level_{n_years_sample}_{target_col}_{column}\"\n",
    "\n",
    "        df_bootstrap_mean.to_csv(os.path.join(PATH_OUTPUT, f\"{filename}.csv\"), index=False)\n",
    "\n",
    "        ## Plot\n",
    "        plt.rcParams.update({'font.size': 18})\n",
    "        fig = plt.figure(figsize = (15, 10))\n",
    "\n",
    "        m = Basemap(projection='lcc', resolution='f', lat_0=47.7, lon_0=13.3, width=6.0E5, height=3.35E5)\n",
    "        m.drawmapboundary()\n",
    "        m.drawcountries(linewidth=2)\n",
    "\n",
    "        m.scatter(df_bootstrap_mean['lon'], df_bootstrap_mean['lat'], c=df_bootstrap_mean[column], cmap=cmap, s=2, latlon=True, vmin=vmin, vmax=vmax)\n",
    "\n",
    "        plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.png\"), bbox_inches=\"tight\")\n",
    "        plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "        plt.rcParams.update({'font.size': 24})\n",
    "        fig = plt.figure(figsize=(3, 8))\n",
    "        ax1 = fig.add_axes([0.05, 0.80, 0.2, 0.9])\n",
    "\n",
    "        cb1 = mpl.colorbar.ColorbarBase(\n",
    "                                            ax1,\n",
    "                                            cmap=cmap,\n",
    "                                            extend='max',\n",
    "                                            norm=mpl.colors.Normalize(vmin=vmin, vmax=vmax),\n",
    "                                            orientation='vertical'\n",
    "        )\n",
    "        \n",
    "        if not 'std' in column:\n",
    "            cb1.set_label('hailstone size [cm]')\n",
    "            \n",
    "        plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.png\"), bbox_inches=\"tight\")\n",
    "        plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}_cmap.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "print(\"Fin.\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
