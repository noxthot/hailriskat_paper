{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = os.path.join('..', 'data')\n",
    "PATH_DATA_SOURCE = os.path.join(PATH_DATA, 'processed_data')\n",
    "PATH_SHAPEFILE = os.path.join(PATH_DATA, 'raw_data', 'geodata', 'AUT_adm0.shp')\n",
    "\n",
    "RETURNLEVELS = [2, 3, 5, 10, 14]  # number of years to be sampled\n",
    "NR_SAMPLES = 10 # number of samples per return level (we only have 14 years of data, so we will likely fish in the same pond for some returnlevel-nrsamples combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERS = [d for d in os.listdir(PATH_DATA_SOURCE) if \"dataparquet\" in d]\n",
    "FOLDERS.sort(reverse=True)\n",
    "\n",
    "DIR_DATABUNDLE = FOLDERS[0]\n",
    "PATH_DATABUNDLE = os.path.join(PATH_DATA_SOURCE, DIR_DATABUNDLE)\n",
    "\n",
    "print(PATH_DATABUNDLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUTPUT = os.path.join(PATH_DATA, \"empirical_mesh_returnlevels\", DIR_DATABUNDLE)\n",
    "\n",
    "print(PATH_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PATH_DATABUNDLE)\n",
    "df[\"lat\"] /= 1000000\n",
    "df[\"lon\"] /= 1000000\n",
    "\n",
    "df[\"year\"] = df.date.dt.year\n",
    "\n",
    "meshvars = [t for t in df.columns if (\"data_mehs_\" in t)]\n",
    "targetvars = meshvars + [\"data_mehs2poh\", \"data_poh_max\"]\n",
    "groupvars = [\"lon\", \"lat\"]\n",
    "\n",
    "avail_years = list(df.year.unique())\n",
    "\n",
    "for meshvar in meshvars:\n",
    "    df[meshvar] /= 10  # convert to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austria = gpd.read_file(PATH_SHAPEFILE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PATH_OUTPUT, exist_ok=True)\n",
    "\n",
    "for mehs_column in targetvars:\n",
    "    print(f\"Computing plots for column {mehs_column}\", flush=True)\n",
    "        \n",
    "    for years in RETURNLEVELS:\n",
    "        print(f\"Computing plots for {years} years return level\", flush=True)\n",
    "        dfs_max = []\n",
    "        \n",
    "        for count in range(NR_SAMPLES):\n",
    "            print(\"-\", flush=True, end=\"\")\n",
    "            filter_years = random.sample(avail_years, years)\n",
    "            dfs_max.append(df[df[\"year\"].isin(filter_years)].groupby(groupvars)[mehs_column].max())\n",
    "\n",
    "        print(\"\\n Preparing and saving plot\", flush=True)\n",
    "        \n",
    "        df_max = pd.concat(dfs_max, axis=1).agg(\"mean\", axis=1).reset_index()  # resulting column has no name, but lands at index 2\n",
    "        df_max.columns = list(df_max.columns)[:2] + [\"max_cal_hs\"]\n",
    "    \n",
    "        for clip_to_austria in [False, True]:\n",
    "            print(f\"Clipping to Austria: {clip_to_austria}\", flush=True)\n",
    "            \n",
    "            if clip_to_austria:\n",
    "                geometry = [Point(xy) for xy in zip(df_max['lon'], df_max['lat'])]\n",
    "                gdf = gpd.GeoDataFrame(df_max, geometry=geometry, crs=\"EPSG:4326\")\n",
    "                df_max = gpd.sjoin(gdf, austria, how=\"inner\", predicate='within')[df_max.columns]\n",
    "    \n",
    "            infix_clipped = \"_clipped_AUT\" if clip_to_austria else \"\"\n",
    "    \n",
    "            filename = f\"hailriskat_y{years}_s{NR_SAMPLES}_{mehs_column}{infix_clipped}\"\n",
    "    \n",
    "            df_max_export = df_max.copy()\n",
    "            df_max_export[\"max_cal_hs\"] *= 10  # calibrated hailsizes in export should be in mm\n",
    "            df_max_export[\"max_cal_hs\"] = pd.to_numeric(df_max_export[\"max_cal_hs\"].round(), downcast='integer')\n",
    "            \n",
    "            df_max_export.to_csv(os.path.join(PATH_OUTPUT, f\"{filename}.csv\"), index=False)\n",
    "            \n",
    "            fig = plt.figure(figsize = (15, 10))\n",
    "            \n",
    "            #initialize the Basemap\n",
    "            m = Basemap(projection = 'lcc', resolution='f', lat_0=47.5, lon_0=13.3, width=0.6E6, height=3.7E5)\n",
    "            m.drawmapboundary()\n",
    "            m.drawcountries(linewidth=2)\n",
    "            \n",
    "            m.scatter(df_max['lon'], df_max['lat'], c=df_max['max_cal_hs'], cmap=\"jet\", s=0.5, latlon=True, vmin=1, vmax=6)\n",
    "            \n",
    "            plt.colorbar(label=mehs_column, extend=\"max\")\n",
    "            \n",
    "            plt.savefig(os.path.join(PATH_OUTPUT, f\"{filename}.png\"), bbox_inches=\"tight\")\n",
    "    \n",
    "            plt.close()\n",
    "            \n",
    "            df_max[\"max_cal_hs\"] *= 10  # We want to use mm in csv export\n",
    "            df_max.to_csv(os.path.join(PATH_OUTPUT, f\"{filename}.csv\"))\n",
    "\n",
    "print(\"FIN.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
